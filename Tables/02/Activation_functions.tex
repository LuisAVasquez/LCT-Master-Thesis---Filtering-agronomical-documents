\begin{table}[ht]
    \centering
    \begin{tabular}{p{4cm}|p{8cm}}
        \textbf{Activation Function} &  \textbf{Description} \\ \hline
        Identity &  Returns input as-is \\
        \gls{relu} & Retains positive values, sets negatives to zero \\
        \gls{sigmoid} & Maps input to a value between 0 and 1 \\
        \gls{softmax} & Converts input into a probability distribution over multiple classes \\
        \gls{tanh} & Maps input to a value between -1 and 1 \\
    \end{tabular}
    \caption{Common activation functions}
    \label{tab:02_nn_common_activation_functions}
\end{table}
